use std::array::truncate;

use std::crypto::blake2s;
use std::crypto::pedersen;

use std::convert::from_bits_field;
use std::convert::from_bits_unsigned;

use std::convert::to_bits;
const PUBKEY_BYTES: u16 = 44;
const PUBKEY_BITS: u16 = (8 as u16) * PUBKEY_BYTES;

const HASH_BYTES: u16 = 32;
const HASH_BITS: u16 = (8 as u16) * HASH_BYTES;

const BYTE_BITS: u16 = 8;

const U32_BYTES: u16 = 4;
const U32_BITS: u16 = U32_BYTES * BYTE_BITS;

const U128_BYTES: u16 = 16;
const U128_BITS: u16 = U128_BYTES * BYTE_BITS;

const STATE_BYTES: u16 = PUBKEY_BYTES + U32_BYTES + PUBKEY_BYTES;
const STATE_BITS: u16 = STATE_BYTES * BYTE_BITS;

const REF_BITS: u16 = HASH_BITS;

const NONCE_BYTES: u16 = HASH_BYTES + U32_BYTES + U32_BYTES;
const NONCE_BITS: u16 = NONCE_BYTES * BYTE_BITS;

type HashDigestBytes = [u8; HASH_BYTES];
type HashDigestBits = [bool; HASH_BITS];

type PrivacySalt = [bool; HASH_BITS];
//Debug functions to convert bit arrays to byte arrays

fn u32_to_bytes(bits: [bool; U32_BITS]) -> [u8; U32_BYTES] {
    let mut u32_bytes = [0 as u8; U32_BYTES];

    for i in 0..U32_BYTES {
        let mut byte_bits = [false; BYTE_BITS];
        for j in 0..BYTE_BITS {
            byte_bits[j] = bits[BYTE_BITS * i + j];
        }
        u32_bytes[i] = std::convert::from_bits_unsigned(byte_bits);
    }

    u32_bytes
}

fn digest_to_bytes(digest: [bool; HASH_BITS]) -> [u8; HASH_BYTES] {
    let mut hash_bytes = [0 as u8; HASH_BYTES];

    for i in 0..HASH_BYTES {
        let mut byte_bits = [false; BYTE_BITS];
        for j in 0..BYTE_BITS {
            byte_bits[j] = digest[BYTE_BITS * i + j];
        }
        hash_bytes[i] = std::convert::from_bits_unsigned(byte_bits);
    }

    hash_bytes
}

fn hashhash_to_bytes(digest: [bool; HASH_BITS + HASH_BITS]) -> [u8; HASH_BYTES + HASH_BYTES] {
    let mut hash_bytes = [0 as u8; HASH_BYTES + HASH_BYTES];

    for i in 0..(HASH_BYTES + HASH_BYTES) {
        let mut byte_bits = [false; BYTE_BITS];
        for j in 0..BYTE_BITS {
            byte_bits[j] = digest[BYTE_BITS * i + j];
        }
        hash_bytes[i] = std::convert::from_bits_unsigned(byte_bits);
    }

    hash_bytes
}

fn hashref_to_bytes(digest: [bool; HASH_BITS + REF_BITS]) -> [u8; HASH_BYTES + HASH_BYTES] {
    let mut hash_bytes = [0 as u8; HASH_BYTES + HASH_BYTES];

    for i in 0..(HASH_BYTES + HASH_BYTES) {
        let mut byte_bits = [false; BYTE_BITS];
        for j in 0..BYTE_BITS {
            byte_bits[j] = digest[BYTE_BITS * i + j];
        }
        hash_bytes[i] = std::convert::from_bits_unsigned(byte_bits);
    }

    hash_bytes
}

fn hashstate_to_bytes(digest: [bool; HASH_BITS + STATE_BITS]) -> [u8; HASH_BYTES + STATE_BYTES] {
    let mut hash_bytes = [0 as u8; HASH_BYTES + STATE_BYTES];

    for i in 0..(HASH_BYTES + STATE_BYTES) {
        let mut byte_bits = [false; BYTE_BITS];
        for j in 0..BYTE_BITS {
            byte_bits[j] = digest[BYTE_BITS * i + j];
        }
        hash_bytes[i] = std::convert::from_bits_unsigned(byte_bits);
    }

    hash_bytes
}

fn nonce_to_bytes(bits: [bool; NONCE_BITS]) -> [u8; NONCE_BYTES] {
    let mut nonce_bytes = [0 as u8; NONCE_BYTES];

    for i in 0..NONCE_BYTES {
        let mut byte_bits: [bool; 8] = [false; 8];
        for j in 0..(8 as u16) {
            byte_bits[j] = bits[(8 as u16) * i + j];
        }
        nonce_bytes[(i as u16)] = std::convert::from_bits_unsigned(byte_bits);
    }

    nonce_bytes
}
enum ComponentGroupEnum {
    INPUTS_GROUP = 0,
    OUTPUTS_GROUP = 1,
    COMMANDS_GROUP = 2,
    ATTACHMENTS_GROUP = 3,
    NOTARY_GROUP = 4,
    TIMEWINDOW_GROUP = 5,
    SIGNERS_GROUP = 6,
    REFERENCES_GROUP = 7,
    PARAMETERS_GROUP = 8,
}
// Method to compute a nonce based on privacySalt, component group index and component internal index.
// * privacy_salt a PrivacySalt
// * group_index the fixed index (ordinal) of this component group.
// * internal_index the internal index of this object in its corresponding components list.
// return H(privacy_salt || group_index || internal_index))
fn compute_nonce(
    privacy_salt: PrivacySalt,
    group_index: u32,
    internal_index: u32,
) -> [bool; HASH_BITS] {

    let mut nonce = [false; NONCE_BITS];
    for i in 0..HASH_BITS {
        nonce[i] = privacy_salt[i];
    }

    let group_index_bits = to_bits(group_index);
    let internal_index_bits = to_bits(internal_index);

    for i in 0..U32_BITS {
        nonce[HASH_BITS + (i as u16)] = group_index_bits[i];
        nonce[HASH_BITS + U32_BITS + (i as u16)] = internal_index_bits[i];
    }


    blake2s(nonce)
}
const PEDERSEN_DIGEST_BITS: u16 = 254;

// Method to concatenate two hash digests.
fn concatenate_hashes(
    hash1: [bool; HASH_BITS],
    hash2: [bool; HASH_BITS],
) -> [bool; HASH_BITS + HASH_BITS] {
    let mut data = [false; HASH_BITS + HASH_BITS];

    for i in (0 as u16)..HASH_BITS {
        data[i] = hash1[i];
        data[HASH_BITS + i] = hash2[i];
    }
    data
}

// Method to pad pedersen digest with zeros to assure 256 bits digest size globally.
fn pedersen_to_padded_bits(digest: field) -> [bool; HASH_BITS] {
    let mut digest_bits = [false; HASH_BITS];
    let pedersen_bits = to_bits(digest);

    for i in 0..PEDERSEN_DIGEST_BITS {
        digest_bits[(2 as u16) + i] = pedersen_bits[i];
    }

    digest_bits
}
type PubKeyBytes = [u8; PUBKEY_BYTES];
type PubKeyBits = [bool; PUBKEY_BITS];

struct PubKey {
    bytes: PubKeyBytes,
}

impl PubKey {
    fn fingerprint(this: PubKey) -> PubKeyBits {
        let mut pub_key_bits = [false; PUBKEY_BITS];

        for i in (0 as u16)..PUBKEY_BYTES {
            let pk_bits = to_bits(this.bytes[i]);
            for j in (0 as u16)..(8 as u16) {
                pub_key_bits[(8 as u16) * i + j] = pk_bits[j];
            }
        }
        pub_key_bits
    }

    // Method to compute leaf hash on public key values.
    fn compute_leaf_hash(
        this: PubKey,
        privacy_salt: PrivacySalt,
        group_index: u32,
        internal_index: u32,
    ) -> HashDigestBits {
        //fingerprint
        let fingerprint_pub_key = fingerprint(this);

        //compute nonce
        let mut nonce = compute_nonce(privacy_salt, group_index, internal_index);
        let mut message: [bool; HASH_BITS + PUBKEY_BITS] = [false; HASH_BITS + PUBKEY_BITS];

        //message = nonce || signature
        for i in 0..HASH_BITS {
            message[i] = nonce[i];
        }

        for i in 0..PUBKEY_BITS {
            message[HASH_BITS + i] = fingerprint_pub_key[i];
        }

        blake2s(message)
    }
}
struct HashDigest {
    bytes: HashDigestBytes,
}

impl HashDigest {
    fn fingerprint(this: HashDigest) -> HashDigestBits {
        let mut hash_digest_bits = [false; HASH_BITS];

        for i in (0 as u16)..HASH_BYTES {
            let hd_bits = to_bits(this.bytes[i]);
            for j in (0 as u16)..(8 as u16) {
                hash_digest_bits[(8 as u16) * i + j] = hd_bits[j];
            }
        }
        hash_digest_bits
    }

    // Method to compute leaf hash on hash values.
    fn compute_leaf_hash(
        this: HashDigest,
        privacy_salt: PrivacySalt,
        group_index: u32,
        internal_index: u32,
    ) -> HashDigestBits {
        //fingerprint
        let fingerprint_hash_digest = fingerprint(this);

        //compute nonce
        let mut nonce = compute_nonce(privacy_salt, group_index, internal_index);

        let mut message: [bool; HASH_BITS + HASH_BITS] = [false; HASH_BITS + HASH_BITS];

        //message = nonce || hash
        for i in 0..HASH_BITS {
            message[i] = nonce[i];
        }
        for i in 0..HASH_BITS {
            message[HASH_BITS + i] = fingerprint_hash_digest[i];
        }


        blake2s(message)
    }
}
// Merkle tree construction.

fn merkle_2_leaves(leaves: [[bool; HASH_BITS]; 2]) -> [bool; HASH_BITS] {
    pedersen_to_padded_bits(pedersen(concatenate_hashes(leaves[0], leaves[1])).0)
}

fn merkle_4_leaves(leaves: [[bool; HASH_BITS]; 4]) -> [bool; HASH_BITS] {
    let mut new_leaves = [[false; HASH_BITS]; 2];
    for i in 0..2 {
        new_leaves[i] = pedersen_to_padded_bits(
            pedersen(concatenate_hashes(leaves[2 * i], leaves[2 * i + 1])).0,
        );
    }
    merkle_2_leaves(new_leaves)
}
fn merkle_8_leaves(leaves: [[bool; HASH_BITS]; 8]) -> [bool; HASH_BITS] {
    let mut new_leaves = [[false; HASH_BITS]; 4];
    for i in 0..4 {
        new_leaves[i] = pedersen_to_padded_bits(
            pedersen(concatenate_hashes(leaves[2 * i], leaves[2 * i + 1])).0,
        );
    }
    merkle_4_leaves(new_leaves)
}
fn merkle_16_leaves(leaves: [[bool; HASH_BITS]; 16]) -> [bool; HASH_BITS] {
    let mut new_leaves = [[false; HASH_BITS]; 8];
    for i in 0..8 {
        new_leaves[i] = pedersen_to_padded_bits(
            pedersen(concatenate_hashes(leaves[2 * i], leaves[2 * i + 1])).0,
        );
    }
    merkle_8_leaves(new_leaves)
}
type RefBits  = [bool; REF_BITS];
type StateBits  = [bool; STATE_BITS];

struct Party {
    owning_key: PubKey,
}

struct Data {
    owner: Party,
    value: i32,
}

//This struct follows the structure in the original Corda TransactionState structure. The fields
// contractCN, encumbrance and constraint are commented out and declared bool intentionally to
// reserve their place in the structure. In the current implementation we don't use these fields,
// if they are going to be included, they should be declared with the corresponding data type.
struct TransactionState {
    data: Data,
    //contractCN: bool,
    notary: Party,
    //encumbrance: bool,
    //constraint: bool,
}

struct ZKStateRef {
    id: HashDigest,
}

struct ZKStateAndRef {
    state: TransactionState,
    reference: ZKStateRef,
}

struct ZKStateAndRefPaddingWrapper {
    content: ZKStateAndRef,
    is_filler: bool,
}

impl ZKStateRef {
    fn fingerprint(value: ZKStateRef) -> RefBits{
        HashDigest::fingerprint(value.id)
    }

    fn compute_leaf_hash(
        this: ZKStateRef,
        privacy_salt: PrivacySalt,
        group_index: u32,
        internal_index: u32,
    ) -> HashDigestBits {
        //fingerprint
        let fingerprint_ref = fingerprint(this);

        //compute nonce
        let mut nonce = compute_nonce(privacy_salt, group_index, internal_index);

        // message = nonce || ref
        let mut message: [bool; HASH_BITS + REF_BITS] = [false; HASH_BITS + REF_BITS];
        for i in 0..HASH_BITS {
            message[i] = nonce[i];
        }
        for i in 0..REF_BITS {
            message[HASH_BITS + i] = fingerprint_ref[i];
        }
        blake2s(message)
    }
}


///This part is currently commented out since it is not used.
/// However, we will need it in future for the backchain concept.
// impl TransactionState {
//     fn fingerprint_state(state: TransactionState) -> [bool; STATE_BITS] {
//         let mut result = [false; STATE_BITS];
//
//         //state_bits = dataOwner_owning_key || value || notary_owning_key
//         //dataOwner_owning_key
//         result[0..PUBKEY_BITS] = convert_pub_key_to_bits(state.data.owner.owning_key);
//         //value
//         result[PUBKEY_BITS..(PUBKEY_BITS + U32_BITS)] = to_bits(state.data.value);
//         //notary_owning_key
//         result[(PUBKEY_BITS + U32_BITS)..STATE_BITS] =
//             convert_pub_key_to_bits(state.notary.owning_key);
//
//         result
//     }
//
//     fn compute_leaf_hash_state(
//         value: StateBits,
//         privacy_salt: PrivacySalt,
//         group_index: u32,
//         internal_index: u32,
//     ) -> HashDigestBits {
//
//         //compute nonce
//         let mut nonce = compute_nonce(privacy_salt, group_index, internal_index);
//
//         // message = nonce || state
//         let mut message = [false; HASH_BITS + STATE_BITS];
//
//         //message = nonce || state nonce || state
//         for i in 0..HASH_BITS {
//             message[i] = nonce[i];
//         }
//
//         for i in 0..STATE_BITS {
//             message[HASH_BITS + i] = value[i];
//         }
//         blake2s(message)
//     }
// }
const INPUT_GROUP_SIZE: u16 = 2;

struct InputsComponentGroup {
    components: [ZKStateAndRefPaddingWrapper; INPUT_GROUP_SIZE],
    group_hash: HashDigest,
}

impl InputsComponentGroup {
    fn compute_leaf_hashes(
        inputs: InputsComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> [HashDigestBits; INPUT_GROUP_SIZE] {
        let mut component_leaf_hashes = [[false; HASH_BITS]; INPUT_GROUP_SIZE];

        for i in (0 as u32)..(INPUT_GROUP_SIZE as u32) {
            component_leaf_hashes[i] = ZKStateRef::compute_leaf_hash(
                inputs.components[i].content.reference,
                privacy_salt,
                ComponentGroupEnum::INPUTS_GROUP as u32,
                i as u32,
            );
        }
        component_leaf_hashes
    }

    fn compute_component_group_hash(
        inputs: InputsComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> HashDigestBits {
        let component_leaf_hashes = compute_leaf_hashes(inputs, privacy_salt);

        //Since INPUT_GROUP_SIZE = 2, we use this Merkle function.
        //If INPUT_GROUP_SIZE is different choose the appropriate merkle_util function.
        //If INPUT_GROUP_SIZE is odd, apply zero padding until the number of leaf hashes equal to the next power of 2.
        merkle_2_leaves(component_leaf_hashes)
    }
}
const OUTPUT_GROUP_SIZE: u16 = 2;

struct OutputsComponentGroup {
    components: [ZKStateAndRefPaddingWrapper; OUTPUT_GROUP_SIZE],
    group_hash: HashDigest,
}

impl OutputsComponentGroup {
    fn compute_leaf_hashes(
        outputs: OutputsComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> [HashDigestBits; OUTPUT_GROUP_SIZE] {
        let mut component_leaf_hashes = [[false; HASH_BITS]; OUTPUT_GROUP_SIZE];

        for i in (0 as u32)..(OUTPUT_GROUP_SIZE as u32) {
            component_leaf_hashes[i] = ZKStateRef::compute_leaf_hash(
                outputs.components[i].content.reference,
                privacy_salt,
                ComponentGroupEnum::OUTPUTS_GROUP as u32,
                i as u32,
            );
        }
        component_leaf_hashes
    }

    fn compute_component_group_hash(
        outputs: OutputsComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> HashDigestBits {
        let component_leaf_hashes = compute_leaf_hashes(outputs, privacy_salt);

        merkle_2_leaves(component_leaf_hashes)
    }
}
const REFERENCE_GROUP_SIZE: u16 = 2;

struct ReferencesComponentGroup {
    components: [ZKStateAndRefPaddingWrapper; REFERENCE_GROUP_SIZE],
    group_hash: HashDigest,
}

impl ReferencesComponentGroup {
    fn compute_leaf_hashes(
        references: ReferencesComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> [HashDigestBits; REFERENCE_GROUP_SIZE] {
        let mut component_leaf_hashes = [[false; HASH_BITS]; REFERENCE_GROUP_SIZE];

        for i in (0 as u32)..(REFERENCE_GROUP_SIZE as u32) {
            component_leaf_hashes[i] = ZKStateRef::compute_leaf_hash(
                references.components[i].content.reference,
                privacy_salt,
                ComponentGroupEnum::REFERENCES_GROUP as u32,
                i as u32,
            );
        }
        component_leaf_hashes
    }

    fn compute_component_group_hash(
        references: ReferencesComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> HashDigestBits {
        let component_leaf_hashes = compute_leaf_hashes(references, privacy_salt);

        merkle_2_leaves(component_leaf_hashes)
    }
}
const COMMAND_GROUP_SIZE: u16 = 1;
const COMMAND_BITS: u16 = U32_BITS;

type CommandBits = [bool; U32_BITS];

enum CommandData {
    CREATE = 0,
    MOVE = 1,
}
impl CommandData {
    fn fingerprint(this: CommandData) -> CommandBits {
        to_bits(this as u32)
    }

    fn compute_leaf_hash(
        this: CommandData,
        privacy_salt: PrivacySalt,
        group_index: u32,
        internal_index: u32,
    ) -> HashDigestBits {
        //fingerprint
        let fingerprint_command_data = fingerprint(this);

        //compute nonce
        let mut nonce = compute_nonce(privacy_salt, group_index, internal_index);
        let mut message: [bool; HASH_BITS + U32_BITS] = [false; HASH_BITS + U32_BITS];

        //message = nonce || command
        for i in 0..HASH_BITS {
            message[i] = nonce[i];
        }
        for i in 0..U32_BITS {
            message[HASH_BITS + i] = fingerprint_command_data[i];
        }

        blake2s(message)
    }
}

struct CommandPaddingWrapper {
    content: CommandData,
    is_filler: bool,
}

struct CommandsComponentGroup {
    components: [CommandPaddingWrapper; COMMAND_GROUP_SIZE],
    group_hash: HashDigest,
}

impl CommandsComponentGroup {
    fn compute_leaf_hashes(
        commands: CommandsComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> [HashDigestBits; COMMAND_GROUP_SIZE] {
        let mut component_leaf_hashes = [[false; HASH_BITS]; COMMAND_GROUP_SIZE];

        for i in (0 as u32)..(COMMAND_GROUP_SIZE as u32) {
            component_leaf_hashes[i] = CommandData::compute_leaf_hash(
                commands.components[i].content,
                privacy_salt,
                ComponentGroupEnum::COMMANDS_GROUP as u32,
                i as u32,
            );
        }
        component_leaf_hashes
    }

    fn compute_component_group_hash(
        commands: CommandsComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> HashDigestBits {
        let component_leaf_hashes = compute_leaf_hashes(commands, privacy_salt);

        //When the number of leaves is one, we pad the leaf with zeros from the right first
        //and use padded input in the merkle_root computation.
        let mut padded_leaves = [[false; HASH_BITS]; 2];
        padded_leaves[0] = component_leaf_hashes[0];

        merkle_2_leaves(padded_leaves)
    }
}
const ATTACHMENT_GROUP_SIZE: u16 = 2;

struct AttachmentPaddingWrapper {
    content: HashDigest,
    is_filler: bool,
}

struct AttachmentsComponentGroup {
    components: [AttachmentPaddingWrapper; ATTACHMENT_GROUP_SIZE],
    group_hash: HashDigest,
}

impl AttachmentsComponentGroup {
    fn compute_leaf_hashes(
        attachments: AttachmentsComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> [HashDigestBits; ATTACHMENT_GROUP_SIZE] {
        let mut component_leaf_hashes = [[false; HASH_BITS]; ATTACHMENT_GROUP_SIZE];

        for i in (0 as u32)..(ATTACHMENT_GROUP_SIZE as u32) {
            component_leaf_hashes[i] = HashDigest::compute_leaf_hash(
                attachments.components[i].content,
                privacy_salt,
                ComponentGroupEnum::ATTACHMENTS_GROUP as u32,
                i as u32,
            );
        }

        component_leaf_hashes
    }

    fn compute_component_group_hash(
        attachments: AttachmentsComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> HashDigestBits {
        let component_leaf_hashes = compute_leaf_hashes(attachments, privacy_salt);

        merkle_2_leaves(component_leaf_hashes)
    }
}
struct NotaryPaddingWrapper {
    content: Party,
    is_filler: bool,
}

struct NotaryComponentGroup {
    component: NotaryPaddingWrapper,
    group_hash: HashDigest,
}

impl NotaryComponentGroup {
    fn compute_component_group_hash(
        notary: NotaryComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> HashDigestBits {
        let component_leaf_hash = PubKey::compute_leaf_hash(
            notary.component.content.owning_key,
            privacy_salt,
            ComponentGroupEnum::NOTARY_GROUP as u32,
            0 as u32,
        );

        //When the number of leaves is one, we pad the leaf with zeros from the right first
        //and use padded input in the merkle_root computation.
        let mut padded_leaves = [[false; HASH_BITS]; 2];
        padded_leaves[0] = component_leaf_hash;

        merkle_2_leaves(padded_leaves)
    }
}
const TIME_WINDOW_BYTES: u16 = 24;
const TIME_WINDOW_BITS: u16 = (BYTE_BITS as u16) * TIME_WINDOW_BYTES;

type TimeWindowBytes = [u8; TIME_WINDOW_BYTES];
type TimeWindowBits = [bool; TIME_WINDOW_BITS];

struct TimeWindow {
    bytes: TimeWindowBytes,
}

impl TimeWindow {
    fn fingerprint(this: TimeWindow) -> TimeWindowBits {
        let mut result = [false; TIME_WINDOW_BITS];

        for i in (0 as u16)..TIME_WINDOW_BYTES {
            let time_window_bits = to_bits(this.bytes[i]);
            for j in (0 as u16)..(8 as u16) {
                result[i * (8 as u16) + j] = time_window_bits[j];
            }
        }
        result
    }

    fn compute_leaf_hash(
        this: TimeWindow,
        privacy_salt: PrivacySalt,
        group_index: u32,
        internal_index: u32,
    ) -> HashDigestBits {
        //fingerprint
        let fingerprint_time_window = fingerprint(this);

        //compute nonce
        let mut nonce = compute_nonce(privacy_salt, group_index, internal_index);
        let mut message: [bool; HASH_BITS + TIME_WINDOW_BITS] =
            [false; HASH_BITS + TIME_WINDOW_BITS];

        //message = nonce || signature
        for i in 0..HASH_BITS {
            message[i] = nonce[i];
        }
        for i in 0..TIME_WINDOW_BITS {
            message[HASH_BITS + i] = fingerprint_time_window[i];
        }

        blake2s(message)
    }
}

struct TimeWindowPaddingWrapper {
    content: TimeWindow,
    is_filler: bool,
}

struct TimeWindowComponentGroup {
    component: TimeWindowPaddingWrapper,
    group_hash: HashDigest,
}

impl TimeWindowComponentGroup {
    fn compute_component_group_hash(
        time_window: TimeWindowComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> HashDigestBits {
        let component_leaf_hash = TimeWindow::compute_leaf_hash(
            time_window.component.content,
            privacy_salt,
            ComponentGroupEnum::TIMEWINDOW_GROUP as u32,
            0 as u32,
        );

        //When the number of leaves is one, we pad the leaf with zeros from the right first
        //and use padded input in the merkle_root computation.
        let mut padded_leaves = [[false; HASH_BITS]; 2];
        padded_leaves[0] = component_leaf_hash;

        merkle_2_leaves(padded_leaves)
    }
}
struct ParameterPaddingWrapper {
    content: HashDigest,
    is_filler: bool,
}

struct ParametersComponentGroup {
    component: ParameterPaddingWrapper,
    group_hash: HashDigest,
}

impl ParametersComponentGroup {
    fn compute_component_group_hash(
        parameters: ParametersComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> HashDigestBits {
        let component_leaf_hash = HashDigest::compute_leaf_hash(
            parameters.component.content,
            privacy_salt,
            ComponentGroupEnum::PARAMETERS_GROUP as u32,
            0 as u32,
        );

        //When the number of leaves is one, we pad the leaf with zeros from the right first
        //and use padded input in the merkle_root computation.
        let mut padded_leaves = [[false; HASH_BITS]; 2];
        padded_leaves[0] = component_leaf_hash;

        merkle_2_leaves(padded_leaves)
    }
}
const SIGNER_GROUP_SIZE: u16 = 2;
const SIGNER_BITS: u16 = PUBKEY_BITS;

struct SignerPaddingWrapper {
    content: PubKey,
    is_filler: bool,
}

struct SignersComponentGroup {
    components: [SignerPaddingWrapper; SIGNER_GROUP_SIZE],
    group_hash: HashDigest,
}

impl SignersComponentGroup {
    fn compute_leaf_hashes(
        signers: SignersComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> [HashDigestBits; SIGNER_GROUP_SIZE] {
        let mut component_leaf_hashes = [[false; HASH_BITS]; SIGNER_GROUP_SIZE];

        for i in (0 as u32)..(SIGNER_GROUP_SIZE as u32) {
            component_leaf_hashes[i] = PubKey::compute_leaf_hash(
                signers.components[i].content,
                privacy_salt,
                ComponentGroupEnum::SIGNERS_GROUP as u32,
                i as u32,
            );
        }
        component_leaf_hashes
    }

    fn compute_component_group_hash(
        signers: SignersComponentGroup,
        privacy_salt: PrivacySalt,
    ) -> HashDigestBits {
        let component_leaf_hashes = compute_leaf_hashes(signers, privacy_salt);

        merkle_2_leaves(component_leaf_hashes)
    }
}
struct ZKProverTransaction {
    inputs: InputsComponentGroup,
    outputs: OutputsComponentGroup,
    references: ReferencesComponentGroup,
    commands: CommandsComponentGroup,
    attachments: AttachmentsComponentGroup,
    notary: NotaryComponentGroup,
    time_window: TimeWindowComponentGroup,
    parameters: ParametersComponentGroup,
    signers: SignersComponentGroup,
    privacy_salt: HashDigest,
}

struct Witness {
    transaction: ZKProverTransaction,
}
const COMPONENT_GROUP_SIZE: u8 = 9;

// Auxiliary method to validate a GroupHash
// * computed digest that is computed from witness.
// * received digest that is received within the witness.
// return bool If the computed value is equal to the one received then the function returns true. Otherwise, returns false.
fn validate_group_hash(computed: HashDigestBits, received: HashDigestBits) -> bool {

    let mut is_equal = true;

    for i in 0..HASH_BITS {
        if computed[i] != received[i] {
            is_equal = false;
        }
    }
    is_equal
}

// Method to validate group hashes.
// * component_group_hashes that are computed from the witness ZKProverTransaction.
// * zk_prover_transaction  that contains component group hashes computed by the prover.
// If one component_group_hash value cannot be validated then the execution terminates.
fn validate_group_hashes(
    component_group_hashes: [HashDigestBits; COMPONENT_GROUP_SIZE],
    zk_prover_transaction: ZKProverTransaction,
) {
    //Validate component hashes
    let validate_input = validate_group_hash(
        component_group_hashes[ComponentGroupEnum::INPUTS_GROUP],
        HashDigest::fingerprint(zk_prover_transaction.inputs.group_hash),
    );

    assert!(
        validate_input,
        "Failed computation: The computed input group hash does not match the received group hash."
    );

    let validate_output = validate_group_hash(
        component_group_hashes[ComponentGroupEnum::OUTPUTS_GROUP],
        HashDigest::fingerprint(zk_prover_transaction.outputs.group_hash),
    );

    assert!(validate_output, "Failed computation: The computed output group hash does not match the received group hash.");

    let validate_command = validate_group_hash(
        component_group_hashes[ComponentGroupEnum::COMMANDS_GROUP],
        HashDigest::fingerprint(zk_prover_transaction.commands.group_hash),
    );

    assert!(validate_command, "Failed computation: The computed command group hash does not match the received group hash.");

    let validate_attachment = validate_group_hash(
        component_group_hashes[ComponentGroupEnum::ATTACHMENTS_GROUP],
        HashDigest::fingerprint(zk_prover_transaction.attachments.group_hash),
    );

    assert!(validate_attachment, "Failed computation: The computed attachment group hash does not match the received group hash.");

    let validate_notary = validate_group_hash(
        component_group_hashes[ComponentGroupEnum::NOTARY_GROUP],
        HashDigest::fingerprint(zk_prover_transaction.notary.group_hash),
    );

    assert!(validate_notary, "Failed computation: The computed notary group hash does not match the received group hash.");

    let validate_time_window = validate_group_hash(
        component_group_hashes[ComponentGroupEnum::TIMEWINDOW_GROUP],
        HashDigest::fingerprint(zk_prover_transaction.time_window.group_hash),
    );

    assert!(validate_time_window, "Failed computation: The computed time window group hash does not match the received group hash.");

    let validate_signers = validate_group_hash(
        component_group_hashes[ComponentGroupEnum::SIGNERS_GROUP],
        HashDigest::fingerprint(zk_prover_transaction.signers.group_hash),
    );

    assert!(validate_signers, "Failed computation: The computed signers group hash does not match the received group hash.");

    let validate_reference = validate_group_hash(
        component_group_hashes[ComponentGroupEnum::REFERENCES_GROUP],
        HashDigest::fingerprint(zk_prover_transaction.references.group_hash),
    );

    assert!(validate_reference, "Failed computation: The computed reference group hash does not match the received group hash.");

    let validate_parameters = validate_group_hash(
        component_group_hashes[ComponentGroupEnum::PARAMETERS_GROUP],
        HashDigest::fingerprint(zk_prover_transaction.parameters.group_hash),
    );

    assert!(validate_parameters, "Failed computation: The computed parameters group hash does not match the received group hash.");
}
fn build_merkle_tree(
    zk_prover_transaction: ZKProverTransaction,
) -> HashDigestBits {

    //Fingerprint for privacy salt
    let privacy_salt = HashDigest::fingerprint(zk_prover_transaction.privacy_salt);

    let mut component_group_hashes = [[false; HASH_BITS]; COMPONENT_GROUP_SIZE];

    component_group_hashes[ComponentGroupEnum::INPUTS_GROUP] =
        InputsComponentGroup::compute_component_group_hash(zk_prover_transaction.inputs, privacy_salt);
    component_group_hashes[ComponentGroupEnum::OUTPUTS_GROUP] =
        OutputsComponentGroup::compute_component_group_hash(zk_prover_transaction.outputs, privacy_salt);
    component_group_hashes[ComponentGroupEnum::COMMANDS_GROUP] =
        CommandsComponentGroup::compute_component_group_hash(zk_prover_transaction.commands, privacy_salt);
    component_group_hashes[ComponentGroupEnum::ATTACHMENTS_GROUP] =
        AttachmentsComponentGroup::compute_component_group_hash(zk_prover_transaction.attachments, privacy_salt);
    component_group_hashes[ComponentGroupEnum::NOTARY_GROUP] =
        NotaryComponentGroup::compute_component_group_hash(zk_prover_transaction.notary, privacy_salt);
    component_group_hashes[ComponentGroupEnum::TIMEWINDOW_GROUP] =
        TimeWindowComponentGroup::compute_component_group_hash(zk_prover_transaction.time_window, privacy_salt);
    component_group_hashes[ComponentGroupEnum::SIGNERS_GROUP] =
        SignersComponentGroup::compute_component_group_hash(zk_prover_transaction.signers, privacy_salt);
    component_group_hashes[ComponentGroupEnum::REFERENCES_GROUP] =
        ReferencesComponentGroup::compute_component_group_hash(zk_prover_transaction.references, privacy_salt);
    component_group_hashes[ComponentGroupEnum::PARAMETERS_GROUP] =
        ParametersComponentGroup::compute_component_group_hash(zk_prover_transaction.parameters, privacy_salt);

    //Validate component group hashes
    //This function is currently disabled since witness file is all zeros.
    validate_group_hashes(component_group_hashes, zk_prover_transaction);

    // There are 9 component groups.
    // Pad it from the right with as many zero hashes to get a power of two number of leaves.
    // This is how Corda Merkle tree construction works.
    let mut component_leaves = [[false; HASH_BITS]; 16];
    for i in 0..COMPONENT_GROUP_SIZE {
        component_leaves[i] = component_group_hashes[i];
    }

    merkle_16_leaves(component_leaves)
}
//Temporary function to test isFiller attribute
fn check_contract_rules(value: ZKProverTransaction) {
    //Check if inputs total is equal to outputs total
    let mut input_value_sum: i32 = 0;
    let mut output_value_sum: i32 = 0;

    for i in 0..INPUT_GROUP_SIZE {
        if !value.inputs.components[i].is_filler {
            input_value_sum = input_value_sum + value.inputs.components[i].content.state.data.value;
        }
    }

    for i in 0..OUTPUT_GROUP_SIZE {
        if !value.outputs.components[i].is_filler {
            output_value_sum =
                output_value_sum + value.outputs.components[i].content.state.data.value;
        }
    }

    assert!(
        input_value_sum == output_value_sum,
        "Failed requirement: the total value of the inputs and outputs should be equal"
    );
}
struct PublicInput {
    transaction_id: HashDigest,
}

fn main(witness: Witness) -> PublicInput {
    //Check contract rules
    check_contract_rules(witness.transaction);

    //Compute the transaction id
    let root_hash = build_merkle_tree(witness.transaction);

    PublicInput {
        transaction_id: HashDigest {  bytes: digest_to_bytes(root_hash), },
    }
}
